<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Doan Nguyen</title>
    <link>https://doannguyentrong.github.io/posts/</link>
    <description>Recent content in Posts on Doan Nguyen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>nguyentrongdoan.0@gmail.com (Doan Nguyen)</managingEditor>
    <webMaster>nguyentrongdoan.0@gmail.com (Doan Nguyen)</webMaster>
    <lastBuildDate>Sun, 12 May 2019 12:14:34 +0600</lastBuildDate><atom:link href="https://doannguyentrong.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GDB - To debug your C&#43;&#43; ROS code more efficient</title>
      <link>https://doannguyentrong.github.io/posts/gdb-debugging-ros/</link>
      <pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate>
      <author>nguyentrongdoan.0@gmail.com (Doan Nguyen)</author>
      <guid>https://doannguyentrong.github.io/posts/gdb-debugging-ros/</guid>
      <description>In general, gbd is a very powerful tool for debugging C++ at runtime. In order to use it as you are developing your C++ ROS code, you need to do some extra steps.
I actually learned this trick from a colleague, and want to save it for future use by writing this post.
Step 1: Compile your code in debug mode. catkin build your_ros_pkg -DCMAKE_BUILD_TYPE=Debug Step 2: Run your node with gdb.</description>
    </item>
    
    <item>
      <title>Inference on edge: tensorflow lite C&#43;&#43; and GPU/CPU/Hexagon DSP</title>
      <link>https://doannguyentrong.github.io/posts/tensorflow-lite-object-detection-cpp/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate>
      <author>nguyentrongdoan.0@gmail.com (Doan Nguyen)</author>
      <guid>https://doannguyentrong.github.io/posts/tensorflow-lite-object-detection-cpp/</guid>
      <description>Introduction As one of 10 winning startups of the Qualcomm Vietnam Innovative Challenge 2020, I have the chance to use the Qualcomm RB5 board to deploy our autonomous driving system for Automated Guided Vehicles (AGV). If you don&amp;rsquo;t know about AGV and the challenge, you can quickly found a good explanation using Google search.
The main reason which urges me to write this post is that there is a limited number of tutorials you can found online on how to use TensorFlow lite C++ even the homepage of the TensorFlow package.</description>
    </item>
    
    <item>
      <title>Make a conversation between two ESP32 using MQTT protocol</title>
      <link>https://doannguyentrong.github.io/posts/test-two-esp32-making-conversation/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      <author>nguyentrongdoan.0@gmail.com (Doan Nguyen)</author>
      <guid>https://doannguyentrong.github.io/posts/test-two-esp32-making-conversation/</guid>
      <description>Make a conversation between two ESP32 using MQTT protocol Introduction I got two ESP32 from a China shop for just $10 including the shipping fee to the US. ESP32 is a very powerful computer with a dual-core XtensaÂ® 32-bit LX6 240MHz MCU, even more powerful than a supercomputer in the 90s. Also, 448 KB of ROM and 520 KB of on-chip SRAM is abundant for embedded programs (mine are ESP32-WROOM-32D).</description>
    </item>
    
    <item>
      <title>A single framework for inference from different pre-trained models (Caffe, MXnet, Darknet, Tensorflow, ...)</title>
      <link>https://doannguyentrong.github.io/posts/opencv-dnn-inference-package/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      <author>nguyentrongdoan.0@gmail.com (Doan Nguyen)</author>
      <guid>https://doannguyentrong.github.io/posts/opencv-dnn-inference-package/</guid>
      <description>Object Detection and Localization from overhead cameras in fixed area This micropackage includes:
object_detector.py: A wraper of opencv dnn module for different sources of pre-trained models: caffe, tensorflow or darknet &amp;hellip; You can use the same framework, which contains only 2 methods: forward() and post_process(), for all models from different architectures. localizer.py: A simple localization algorithm for overhead camera in fixed area You can:
load the interested model in and use it directly to infer from an input.</description>
    </item>
    
  </channel>
</rss>
