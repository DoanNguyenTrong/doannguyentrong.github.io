<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Personal blog of Doan Nguyen">
  <meta name="author" content="Doan Nguyen" />
  <meta property="title" content="Doan Nguyen" />

  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML"></script>
  <!-- plugins -->
  
  <link rel="stylesheet" href="https://doannguyentrong.github.io/plugins/style.css ">
  
  <!--Favicon-->
  
  
  <link rel="icon" href="https://doannguyentrong.github.io/images/favicon.png " type="image/x-icon">
  <title>Inference on edge: tensorflow lite C&#43;&#43; and GPU/CPU/Hexagon DSP </title>
</head><body><header> 
  
  <nav class="navbar navbar-expand-md navbar-light bg-light fixed-top">
      <div class="container-fluid">
          
          <div class="navbar-header">
              <a class="navbar-brand" href="https://doannguyentrong.github.io/"><img src="https://doannguyentrong.github.io/images/author.png" alt="Doan Nguyen"></a>
          </div>
            
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive">
              <span class="navbar-toggler-icon"></span>
          </button>

          <div class="collapse navbar-collapse" id="navbarResponsive">
              
              <ul class="navbar-nav ml-auto">
                
                
                
                <li class="nav-item">
                  <a class="nav-link" href="https://doannguyentrong.github.io/">Home</a>
                </li>
                
                
                
                <li class="nav-item">
                  <a class="nav-link" href="https://doannguyentrong.github.io/about">About</a>
                </li>
                
                
                
                <li class="nav-item">
                  <a class="nav-link" href="https://doannguyentrong.github.io/posts">Posts</a>
                </li>
                
                
              </ul>
          </div>

      </div>
  </nav>
</header>


<div class="container-fluid padding" style="padding-top: 7em;">
  <div class="row welcome">
      <div class="col-12">
          
          <h3 class="font-tertiary mb-5 text-center">Inference on edge: tensorflow lite C&#43;&#43; and GPU/CPU/Hexagon DSP</h3>
          <div class=" align-center">
            <img src="https://doannguyentrong.github.io/images/author.png" alt="post-thumb" class="img-fluid rounded float-left mr-5 mb-4">
          <p class="font-secondary">Published on Mar 14, 2021 by <span class="text-primary">Doan Nguyen</span></p>
          </div>
          <div class="content text-justify post-text">
            <img class="img-fluid" style="max-width: 100%; height: auto;"  >
            
<div  class="col-sm-12 col-lg-12 col-md-12">
    
        <img class="img-fluid" src="/images/posts/object-detection.jpg"  />
    
    
</div>

<h2 id="introduction">Introduction</h2>
<p>As one of 10 winning startups of the Qualcomm Vietnam Innovative Challenge 2020, I have the chance to use the Qualcomm RB5 board to deploy our autonomous driving system for Automated Guided Vehicles (AGV).
If you don&rsquo;t know about AGV and the challenge, you can quickly found a good explanation using Google search.</p>
<p>The main reason which urges me to write this post is that there is a limited number of tutorials you can found online on how to use TensorFlow lite C++ even the homepage of the TensorFlow package.
I hope this post can save you some time.</p>
<p>In this post, I will show you:</p>
<ul>
<li>How to set up a necessary environment to deploy your neural network inference on a small, low computing power board (like this RB5).
It would also be useful for one who wants to use TensorFlow lite on any other boards like Jetson Nano (TX2/Xavier of course) or Raspberry Pi.</li>
<li>Especially, I will use C++, not Python. Though Python is much easier (there are some Python scripts in the GitHub repo I will share with you in this post), C++ is the language you MUST use on a commercial product as it guarantees you better performance. Also, if you want to enable GPU/Hexagon DSP acceleration, you need to use C++. Python only allows us to use GPU and Google&rsquo;s homemade TPU inference.</li>
<li>Moreover, I will walk you through the needed steps with an explanation so that you can understand the reason behind it, not just throw the code to you.</li>
<li>And most important, I wrapped my code into a class so that you can use it on your project instantly. Here, the class is a header only. It means that you can integrate it into your work without any modification in compile it.</li>
</ul>
<p>Extra:</p>
<ul>
<li>Medium post: <a href="https://nguyentrongdoan.medium.com/inference-on-edge-tensorflow-lite-c-and-gpu-cpu-hexagon-dsp-6e8d65d9690c">https://nguyentrongdoan.medium.com/inference-on-edge-tensorflow-lite-c-and-gpu-cpu-hexagon-dsp-6e8d65d9690c</a></li>
<li>Personal homepage: <a href="https://doannguyentrong.github.io/posts/tensorflow-lite-object-detection-cpp/">https://doannguyentrong.github.io/posts/tensorflow-lite-object-detection-cpp/</a></li>
<li>GitHub repo: <a href="https://github.com/DoanNguyenTrong/object-detection-tflite-cpp">https://github.com/DoanNguyenTrong/object-detection-tflite-cpp</a></li>
</ul>
<h2 id="setup-environment">Setup environment</h2>
<p>Assume that you have installed the OS into your board and can boot into it, will need to do the below steps:</p>
<ul>
<li><a href="https://www.tensorflow.org/lite/guide/build_arm64">Install tensorflow</a> into your board and your host computer. You should have tensorflow on your computer to compile needed libraries that will be used by tensorflow lite. Do it on the board is not a good choice although you definitely can.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/tensorflow/tensorflow.git
</span></span><span style="display:flex;"><span>cd tensorflow
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Use the latest</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#git branch r2.1 remotes/origin/r2.1</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#git checkout r2.1</span>
</span></span><span style="display:flex;"><span>./tensorflow/lite/tools/make/download_dependencies.sh
</span></span><span style="display:flex;"><span>./tensorflow/lite/tools/make/build_aarch64_lib.sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#./tensorflow/lite/tools/make/build_generic_aarch64_lib.sh</span></span></span></code></pre></div>
<p>If you are using an RPi, you should run the sh file tailored for it (which is placed in <code>tensorflow/lite/tools/make/</code>).</p>
<ul>
<li><a href="https://developer.qualcomm.com/project/object-detection-tensorflow-lite">Install opencv</a> onto the board. Pay attention to the comments I place above each command!!!</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt-get install build-essential curl unzip
</span></span><span style="display:flex;"><span>sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev
</span></span><span style="display:flex;"><span>sudo apt-get install libjpeg-dev libpng-dev
</span></span><span style="display:flex;"><span>sudo apt-get install python-numpy libxkbcommon-dev 
</span></span><span style="display:flex;"><span>sudo apt install -y g++ wget unzip
</span></span><span style="display:flex;"><span><span style="color:#75715e"># If you use wayland to display opencv output</span>
</span></span><span style="display:flex;"><span>sudo apt-get install libwayland-client0 libwayland-dev
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Go to your working directory</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># You dont need to strictly follow the below step</span>
</span></span><span style="display:flex;"><span>mkdir /home/src
</span></span><span style="display:flex;"><span>cd /home/src
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># If you use wayland</span>
</span></span><span style="display:flex;"><span>git clone https://github.com/pfpacket/opencv-wayland.git
</span></span><span style="display:flex;"><span>cd opencv-wayland/
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Or you use lastest opencv</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Download and unpack sources</span>
</span></span><span style="display:flex;"><span>wget -O opencv.zip https://github.com/opencv/opencv/archive/master.zip
</span></span><span style="display:flex;"><span>wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/master.zip
</span></span><span style="display:flex;"><span>unzip opencv.zip
</span></span><span style="display:flex;"><span>unzip opencv_contrib.zip
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create build directory and switch into it</span>
</span></span><span style="display:flex;"><span>mkdir -p build <span style="color:#f92672">&amp;&amp;</span> cd build
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Note: You can modify the flags as you want</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Build opencv (latest version)</span>
</span></span><span style="display:flex;"><span>cmake -D CMAKE_BUILD_TYPE<span style="color:#f92672">=</span>Debug -D CMAKE_INSTALL_PREFIX<span style="color:#f92672">=</span>/usr/local -DWITH_IPP<span style="color:#f92672">=</span>OFF -DWITH_WAYLAND<span style="color:#f92672">=</span>ON -DWITH_GTK<span style="color:#f92672">=</span>OFF -DWITH_GSTREAMER<span style="color:#f92672">=</span>ON -DBUILD_opencv_python3<span style="color:#f92672">=</span>yes ..
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>make -j7 <span style="color:#f92672">&amp;&amp;</span> make install
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Build opencv (latest version)</span>
</span></span><span style="display:flex;"><span>cmake -DCMAKE_INSTALL_PREFIX<span style="color:#f92672">=</span>/usr/local -DOPENCV_EXTRA_MODULES_PATH<span style="color:#f92672">=</span>../../opencv_contrib-master/modules -DWITH_IPP<span style="color:#f92672">=</span>OFF -DWITH_GSTREAMER<span style="color:#f92672">=</span>ON -DWITH_GTK<span style="color:#f92672">=</span>OFF -DWITH_WAYLAND<span style="color:#f92672">=</span>ON -DBUILD_opencv_python3<span style="color:#f92672">=</span>yes ..
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>make -j7 <span style="color:#f92672">&amp;&amp;</span> make install</span></span></code></pre></div>
<p>the library is installed to <code>/usr/local/include/opencv/</code></p>
<ul>
<li>Extra: Install freetype2, weston/wayland (in my case)
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt-get install -y freetype2-demos
</span></span><span style="display:flex;"><span>sudo apt-get update <span style="color:#f92672">&amp;&amp;</span> sudo apt-get install weston xwayland</span></span></code></pre></div>
<strong>Note</strong>: You don&rsquo;t need to install reetype2 and weston/wayland if you are working on Jetson or RPi boards.</li>
</ul>
<h2 id="compile-needed-libraries">Compile needed libraries</h2>
<ul>
<li>Build needed libraries on the host machine
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>bazel build --config<span style="color:#f92672">=</span>elinux_aarch64 -c opt --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>bazel build --config<span style="color:#f92672">=</span>elinux_aarch64 -c opt //tensorflow/lite/delegates/hexagon:hexagon_delegate_kernel</span></span></code></pre></div>
You will need to build multiple libraries as tensorflow lite separated into various components.
Here, I have compiled and placed the libraries into <code>WORKING_DIR/tflite/</code> so that you can use them right away.</li>
</ul>
<p>If you get into compiling problem due to missing a library, you need to find and compile the corresponding one. E.g,</p>
<ul>
<li>
<p>If you get this error:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>100%<span style="color:#f92672">]</span> Linking CXX executable webcam-detector
</span></span><span style="display:flex;"><span>../tflite/libhexagon_delegate.so: undefined reference to <span style="color:#e6db74">`</span>vtable <span style="color:#66d9ef">for</span> tflite::HexagonDelegateKernel<span style="color:#960050;background-color:#1e0010">&#39;</span></span></span></code></pre></div></p>
</li>
<li>
<p>Copy the function <code>HexagonDelegateKernel()</code> into your <code>main.cxx</code>. Right click -&gt; Go to Definition (using VSCode IDE in my case). You will find that this function is defined in <code>tensorflow/tensorflow/lite/delegates/hexagon/hexagon_delegate_kernel.h</code>. You need to open the <code>BUILD</code> file in the same repo (<code>tensorflow/tensorflow/lite/delegates/hexagon/BUILD</code>) and find the <code>cc_library</code> that linked with the file and compile it.
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>bazel build --config<span style="color:#f92672">=</span>elinux_aarch64 -c opt //tensorflow/lite/delegates/hexagon:hexagon_delegate_kernel</span></span></code></pre></div></p>
</li>
<li>
<p>Structure of the command:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>bazel build --config<span style="color:#f92672">=</span>elinux_aarch64 -c opt TO_REPO:LIBRARY_NAME</span></span></code></pre></div></p>
</li>
<li>
<p>Clone this repo, compile and run
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/DoanNguyenTrong/object-detection-tflite-cpp.git
</span></span><span style="display:flex;"><span>cd object-detection-tflite-cpp/
</span></span><span style="display:flex;"><span>./compile.sh
</span></span><span style="display:flex;"><span>./object-detector <span style="color:#ae81ff">0</span> dev/video0</span></span></code></pre></div></p>
</li>
</ul>
<h2 id="api-explanation">API explanation</h2>
<ul>
<li>Initiallize:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>ObjectDetector <span style="color:#a6e22e">detector</span>(modelfile, labelfile);
</span></span><span style="display:flex;"><span>detector.readLabels();
</span></span><span style="display:flex;"><span>detector.readModel();
</span></span><span style="display:flex;"><span>detector.configure(<span style="color:#ae81ff">4</span>, delegate_option);</span></span></code></pre></div></li>
</ul>
<p><code>modelfile</code> and <code>labelfile</code> are two strings that point to a delegated model and a label file. <code>4</code> is the number of threads will be used and <code>delegate_option</code> defines which hardware will be used for acceleration(<code>0</code>-GPU and <code>1</code>-Hexagon DSP);</p>
<ul>
<li>Inference and extract objects using NMS method</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> state <span style="color:#f92672">=</span> detector.inference(frame);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (state <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>){
</span></span><span style="display:flex;"><span>    exit(<span style="color:#ae81ff">0</span>);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Object<span style="color:#f92672">&gt;</span> objects <span style="color:#f92672">=</span> detector.extractObjects(<span style="color:#ae81ff">0.3f</span>, <span style="color:#ae81ff">0.5f</span>);</span></span></code></pre></div>
<p><code>0.3f</code> is the score threshold and <code>0.5f</code> is the NMS&rsquo;s threshold.</p>
<ul>
<li>For more information, please take a look into my code.</li>
</ul>
<h2 id="referenceuseful-links">Reference/Useful links</h2>
<ul>
<li>
<p>RB5 object detector with c++,flite, CPU
<a href="https://developer.qualcomm.com/project/object-detection-tensorflow-lite">https://developer.qualcomm.com/project/object-detection-tensorflow-lite</a></p>
</li>
<li>
<p>tflite, GPU
<a href="https://developer.qualcomm.com/blog/tensorflow-lite-inference-edge">https://developer.qualcomm.com/blog/tensorflow-lite-inference-edge</a></p>
</li>
<li>
<p>Hexagon delegate
<a href="https://www.tensorflow.org/lite/performance/hexagon_delegate">https://www.tensorflow.org/lite/performance/hexagon_delegate</a></p>
</li>
<li>
<p>User guide
<a href="https://www.devever.net/~hl/f/80-VB419-108_Hexagon_DSP_User_Guide.pdf">https://www.devever.net/~hl/f/80-VB419-108_Hexagon_DSP_User_Guide.pdf</a></p>
</li>
<li>
<p><a href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/software-reference-manual/machine-learning/tensorflow">https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/software-reference-manual/machine-learning/tensorflow</a></p>
</li>
<li>
<p>ROS 1, hexagon, tflite
<a href="https://github.com/quic/sample-apps-for-Qualcomm-Robotics-RB5-platform/tree/master/HexgonSDK-Image-classification">https://github.com/quic/sample-apps-for-Qualcomm-Robotics-RB5-platform/tree/master/HexgonSDK-Image-classification</a></p>
</li>
<li>
<p>Gstreamer RB5 extensions: <a href="https://source.codeaurora.org/quic/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/tree/gst-plugin-mle?h=LE.UM.4.4.1.r2-01600-QRB5165.0">https://source.codeaurora.org/quic/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/tree/gst-plugin-mle?h=LE.UM.4.4.1.r2-01600-QRB5165.0</a></p>
</li>
</ul>

            <div id="disqus_thread"></div> 
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://doannguyen.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        </div>
        
      </div>
  </div>     
</div>


    </body><footer>
  <div class="container-fluid">
      <div class="row text-center">
          <div class="col-12">
              <h5>&copy;Doan Nguyen, 2022</h5>
              <p>nguyentrongdoan.0@gmail.com</p>
          </div>
      </div>
  </div>
</footer></html>